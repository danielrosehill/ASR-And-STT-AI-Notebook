#!/usr/bin/env python3
"""
STT Fine-Tuning Notebook - Automated Prompt Processing Workflow

This script automates the workflow of processing prompts from the to-run folder,
generating content, categorizing, adding attribution, and archiving.
"""

import os
import sys
import json
import re
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Tuple, Optional
import anthropic
import argparse

# Configuration
REPO_ROOT = Path(__file__).parent.parent
PROMPTS_TO_RUN = REPO_ROOT / "prompts" / "to-run"
PROMPTS_PROCESSED = REPO_ROOT / "prompts" / "processed"
CONFIG_FILE = REPO_ROOT / "workflow-automation" / "config.json"

# Category folders
CATEGORY_FOLDERS = {
    "models": REPO_ROOT / "models",
    "formats": REPO_ROOT / "formats",
    "training-data": REPO_ROOT / "training-data",
    "pitfalls": REPO_ROOT / "pitfalls",
    "fine-tuning": REPO_ROOT / "fine-tuning",
    "recommendations": REPO_ROOT / "recommendations",
    "data-preparation": REPO_ROOT / "data-preparation",
    "ext-ref": REPO_ROOT / "ext-ref"
}

# Attribution templates
ATTRIBUTION_FOOTER = "*Generated by Claude Code - Validate information against current model documentation and benchmarks.*"
ATTRIBUTION_BADGE = "![Written by Claude](https://img.shields.io/badge/Written%20by-Claude-5A67D8?style=flat-square&logo=anthropic)"


class PromptProcessor:
    """Orchestrates the prompt processing workflow"""

    def __init__(self, api_key: Optional[str] = None, dry_run: bool = False):
        self.dry_run = dry_run
        self.api_key = api_key or os.environ.get("ANTHROPIC_API_KEY")
        if not self.api_key:
            raise ValueError("ANTHROPIC_API_KEY not found in environment or provided")

        self.client = anthropic.Anthropic(api_key=self.api_key)
        self.load_config()

    def load_config(self):
        """Load configuration for category keywords"""
        if CONFIG_FILE.exists():
            with open(CONFIG_FILE, 'r') as f:
                self.config = json.load(f)
        else:
            # Default configuration
            self.config = {
                "category_keywords": {
                    "models": ["model", "whisper", "wav2vec", "architecture", "hubert", "conformer", "parakeet"],
                    "formats": ["format", "gguf", "ggml", "quantization", "file format", "export"],
                    "training-data": ["dataset", "audio data", "training data", "data collection", "corpus"],
                    "pitfalls": ["problem", "issue", "mistake", "avoid", "pitfall", "error", "common issue"],
                    "fine-tuning": ["training", "fine-tuning", "hyperparameter", "epoch", "learning rate", "optimizer"],
                    "recommendations": ["recommendation", "best practice", "should", "consider", "advice"],
                    "data-preparation": ["preprocessing", "preparation", "cleaning", "normalization", "augmentation"],
                    "ext-ref": ["resource", "reference", "link", "paper", "documentation", "external"]
                },
                "default_category": "ext-ref"
            }
            self._save_config()

    def _save_config(self):
        """Save configuration to file"""
        CONFIG_FILE.parent.mkdir(parents=True, exist_ok=True)
        with open(CONFIG_FILE, 'w') as f:
            json.dump(self.config, indent=2, fp=f)

    def categorize_prompt(self, prompt_text: str, filename: str) -> str:
        """
        Categorize a prompt based on keywords and content analysis.
        Returns the category name.
        """
        # First try simple keyword matching
        prompt_lower = (prompt_text + " " + filename).lower()
        scores = {}

        for category, keywords in self.config["category_keywords"].items():
            score = sum(1 for keyword in keywords if keyword.lower() in prompt_lower)
            if score > 0:
                scores[category] = score

        if scores:
            # Return category with highest score
            return max(scores, key=scores.get)

        # If no keywords matched, use Claude to categorize
        return self._categorize_with_claude(prompt_text)

    def _categorize_with_claude(self, prompt_text: str) -> str:
        """Use Claude to categorize when keyword matching fails"""
        categorization_prompt = f"""Analyze this prompt about STT (Speech-to-Text) fine-tuning and categorize it into ONE of these categories:

Categories:
- models: About ASR model architectures, specific models (Whisper, Wav2Vec, etc.)
- formats: About file formats, quantization formats (GGUF, GGML, etc.)
- training-data: About datasets, data collection, audio corpus
- pitfalls: About common mistakes, problems to avoid, troubleshooting
- fine-tuning: About training process, hyperparameters, optimization
- recommendations: Best practices, advice, what to consider
- data-preparation: Preprocessing, audio cleaning, normalization, augmentation
- ext-ref: External resources, papers, documentation links

Prompt to categorize:
{prompt_text[:500]}...

Respond with ONLY the category name, nothing else."""

        try:
            message = self.client.messages.create(
                model="claude-sonnet-4-5-20250929",
                max_tokens=50,
                messages=[{"role": "user", "content": categorization_prompt}]
            )

            category = message.content[0].text.strip().lower()

            # Validate category
            if category in CATEGORY_FOLDERS:
                return category
            else:
                print(f"Warning: Claude returned invalid category '{category}', using default")
                return self.config["default_category"]

        except Exception as e:
            print(f"Warning: Categorization failed with error: {e}, using default category")
            return self.config["default_category"]

    def generate_content(self, prompt_text: str) -> str:
        """Generate comprehensive content based on the prompt"""
        system_prompt = """You are a technical expert in Speech-to-Text (STT) fine-tuning, ASR models, and audio ML.

Generate comprehensive, accurate, and well-structured markdown documentation in response to questions about STT fine-tuning.

Guidelines:
- Provide detailed technical information
- Include practical examples where relevant
- Use proper markdown formatting (headers, lists, code blocks, tables)
- Be specific with model names, parameters, and technical details
- Include benchmark numbers when available
- Cite specific tools, libraries, and frameworks
- Structure content logically with clear sections
- Make it suitable for a technical reference notebook

Do NOT include any attribution footer or badges - those will be added automatically."""

        try:
            message = self.client.messages.create(
                model="claude-sonnet-4-5-20250929",
                max_tokens=4096,
                system=system_prompt,
                messages=[{"role": "user", "content": prompt_text}]
            )

            return message.content[0].text.strip()

        except Exception as e:
            raise Exception(f"Content generation failed: {e}")

    def generate_filename(self, prompt_text: str, category: str) -> str:
        """
        Generate an appropriate filename based on the prompt content.
        Format: topic-keywords.md
        """
        # Use Claude to generate a concise filename
        filename_prompt = f"""Based on this prompt about STT fine-tuning, generate a concise, descriptive filename (without extension).

Guidelines:
- Use lowercase
- Use hyphens to separate words
- 2-5 words maximum
- Focus on the main topic
- Make it descriptive but brief
- No special characters except hyphens

Example good filenames:
- "model-selection-criteria"
- "training-data-requirements"
- "quantization-strategies"
- "common-overfitting-issues"

Prompt: {prompt_text[:300]}...

Respond with ONLY the filename (no extension, no quotes), nothing else."""

        try:
            message = self.client.messages.create(
                model="claude-sonnet-4-5-20250929",
                max_tokens=50,
                messages=[{"role": "user", "content": filename_prompt}]
            )

            filename = message.content[0].text.strip()
            # Clean up the filename
            filename = re.sub(r'[^a-z0-9-]', '', filename.lower())
            filename = re.sub(r'-+', '-', filename)  # Remove duplicate hyphens
            filename = filename.strip('-')  # Remove leading/trailing hyphens

            if not filename:
                # Fallback to timestamp-based name
                filename = f"note-{datetime.now().strftime('%Y%m%d-%H%M%S')}"

            return filename + ".md"

        except Exception as e:
            print(f"Warning: Filename generation failed: {e}, using timestamp")
            return f"note-{datetime.now().strftime('%Y%m%d-%H%M%S')}.md"

    def add_attribution(self, content: str, add_badge: bool = True) -> str:
        """Add attribution to generated content"""
        parts = []

        if add_badge:
            parts.append(ATTRIBUTION_BADGE)
            parts.append("")  # Blank line after badge

        parts.append(content)
        parts.append("")  # Blank line before footer
        parts.append("---")
        parts.append("")
        parts.append(ATTRIBUTION_FOOTER)

        return "\n".join(parts)

    def save_content(self, content: str, category: str, filename: str) -> Path:
        """Save generated content to appropriate category folder"""
        category_path = CATEGORY_FOLDERS[category]
        category_path.mkdir(parents=True, exist_ok=True)

        output_path = category_path / filename

        # Handle duplicate filenames
        if output_path.exists():
            base = output_path.stem
            ext = output_path.suffix
            counter = 1
            while output_path.exists():
                output_path = category_path / f"{base}-{counter}{ext}"
                counter += 1

        if not self.dry_run:
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write(content)

        return output_path

    def archive_prompt(self, prompt_path: Path) -> Path:
        """Move processed prompt to processed folder with timestamp"""
        PROMPTS_PROCESSED.mkdir(parents=True, exist_ok=True)

        # Create dated subfolder
        date_folder = PROMPTS_PROCESSED / datetime.now().strftime('%Y-%m')
        date_folder.mkdir(parents=True, exist_ok=True)

        # Generate archive filename with timestamp
        timestamp = datetime.now().strftime('%Y%m%d-%H%M%S')
        archive_name = f"{prompt_path.stem}_{timestamp}{prompt_path.suffix}"
        archive_path = date_folder / archive_name

        if not self.dry_run:
            prompt_path.rename(archive_path)

        return archive_path

    def process_prompt(self, prompt_path: Path) -> Dict:
        """Process a single prompt through the entire workflow"""
        result = {
            "prompt_file": prompt_path.name,
            "success": False,
            "error": None
        }

        try:
            print(f"\n{'='*60}")
            print(f"Processing: {prompt_path.name}")
            print(f"{'='*60}\n")

            # Read prompt
            with open(prompt_path, 'r', encoding='utf-8') as f:
                prompt_text = f.read()

            print(f"Prompt preview: {prompt_text[:200]}...\n")

            # Categorize
            print("üìÅ Categorizing prompt...")
            category = self.categorize_prompt(prompt_text, prompt_path.name)
            print(f"   ‚Üí Category: {category}\n")
            result["category"] = category

            # Generate filename
            print("üìù Generating filename...")
            filename = self.generate_filename(prompt_text, category)
            print(f"   ‚Üí Filename: {filename}\n")
            result["output_filename"] = filename

            # Generate content
            print("‚úçÔ∏è  Generating content...")
            content = self.generate_content(prompt_text)
            print(f"   ‚Üí Generated {len(content)} characters\n")

            # Add attribution
            print("üè∑Ô∏è  Adding attribution...")
            content_with_attribution = self.add_attribution(content)

            # Save content
            print(f"üíæ Saving to {category}/...")
            output_path = self.save_content(content_with_attribution, category, filename)
            print(f"   ‚Üí Saved to: {output_path}\n")
            result["output_path"] = str(output_path)

            # Archive prompt
            print("üì¶ Archiving prompt...")
            archive_path = self.archive_prompt(prompt_path)
            print(f"   ‚Üí Archived to: {archive_path}\n")
            result["archive_path"] = str(archive_path)

            result["success"] = True
            print("‚úÖ Successfully processed!\n")

        except Exception as e:
            result["error"] = str(e)
            print(f"‚ùå Error: {e}\n")

        return result

    def process_all_prompts(self) -> List[Dict]:
        """Process all prompts in the to-run folder"""
        prompt_files = sorted(PROMPTS_TO_RUN.glob("*.txt")) + sorted(PROMPTS_TO_RUN.glob("*.md"))

        if not prompt_files:
            print("No prompts found in to-run folder.")
            return []

        print(f"Found {len(prompt_files)} prompt(s) to process\n")

        results = []
        for prompt_file in prompt_files:
            result = self.process_prompt(prompt_file)
            results.append(result)

        return results

    def print_summary(self, results: List[Dict]):
        """Print processing summary"""
        print("\n" + "="*60)
        print("PROCESSING SUMMARY")
        print("="*60 + "\n")

        successful = [r for r in results if r["success"]]
        failed = [r for r in results if not r["success"]]

        print(f"Total processed: {len(results)}")
        print(f"Successful: {len(successful)}")
        print(f"Failed: {len(failed)}\n")

        if successful:
            print("‚úÖ Successfully processed:")
            for r in successful:
                print(f"   ‚Ä¢ {r['prompt_file']} ‚Üí {r['category']}/{r['output_filename']}")

        if failed:
            print("\n‚ùå Failed:")
            for r in failed:
                print(f"   ‚Ä¢ {r['prompt_file']}: {r['error']}")

        print()


def main():
    parser = argparse.ArgumentParser(
        description="Process STT fine-tuning prompts and generate notebook content"
    )
    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="Show what would be done without actually doing it"
    )
    parser.add_argument(
        "--prompt",
        type=str,
        help="Process a specific prompt file (name only, e.g., 'my-question.txt')"
    )
    parser.add_argument(
        "--api-key",
        type=str,
        help="Anthropic API key (or set ANTHROPIC_API_KEY env var)"
    )

    args = parser.parse_args()

    try:
        processor = PromptProcessor(api_key=args.api_key, dry_run=args.dry_run)

        if args.dry_run:
            print("üîç DRY RUN MODE - No files will be modified\n")

        if args.prompt:
            # Process single prompt
            prompt_path = PROMPTS_TO_RUN / args.prompt
            if not prompt_path.exists():
                print(f"Error: Prompt file '{args.prompt}' not found in to-run folder")
                sys.exit(1)

            result = processor.process_prompt(prompt_path)
            processor.print_summary([result])
        else:
            # Process all prompts
            results = processor.process_all_prompts()
            processor.print_summary(results)

    except Exception as e:
        print(f"Fatal error: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()

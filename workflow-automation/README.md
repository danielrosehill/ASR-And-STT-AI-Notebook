# STT Fine-Tuning Notebook - Workflow Automation

Automated workflow system for processing prompts and generating notebook content.

## Overview

This system automates the complete workflow:

1. **Monitor** `prompts/to-run/` for new prompt files
2. **Categorize** each prompt automatically
3. **Generate** comprehensive content using Claude
4. **Save** to appropriate category folder
5. **Add attribution** (badge + footer)
6. **Archive** processed prompts to `prompts/processed/YYYY-MM/`

## Setup

### 1. Install Dependencies

```bash
cd workflow-automation
pip install -r requirements.txt
```

Or use `uv` for a virtual environment:

```bash
cd workflow-automation
uv venv
source .venv/bin/activate
uv pip install -r requirements.txt
```

### 2. Set API Key

```bash
export ANTHROPIC_API_KEY="your-api-key-here"
```

Or pass it as an argument: `--api-key YOUR_KEY`

### 3. Make Scripts Executable

```bash
chmod +x *.sh
```

## Usage

### Option 1: Batch Processing (One-Time)

Process all prompts in the `to-run` folder once:

```bash
./batch_process.sh
```

### Option 2: Watch Mode (Continuous)

Continuously monitor for new prompts and auto-process:

```bash
./watch_and_process.sh
```

This requires `inotify-tools`:
```bash
sudo apt install inotify-tools
```

### Option 3: Process Single Prompt

```bash
python3 prompt_processor.py --prompt "my-question.txt"
```

### Option 4: Dry Run (Preview)

See what would happen without making changes:

```bash
python3 prompt_processor.py --dry-run
```

## Creating Prompts

### Manual Creation

1. Create a `.txt` or `.md` file in `prompts/to-run/`
2. Write your question/prompt
3. Run batch processing or wait for watch mode to detect it

### Using Helper Script

```bash
./create_prompt.sh
```

This interactive script will:
- Prompt for topic keywords
- Generate a properly-named file
- Accept multiline input
- Save to `to-run` folder

## File Naming Conventions

### Prompt Files (Input)

**Format**: `YYYYMMDD-topic-keywords.txt` or `.md`

**Examples**:
- `20251121-model-comparison.txt`
- `20251121-quantization-formats.md`
- `20251121-training-data-volume.txt`

**Guidelines**:
- Start with date for chronological sorting
- Use lowercase
- Use hyphens to separate words
- Keep topic concise (2-5 words)

### Output Files (Generated Notes)

**Format**: `topic-keywords.md` (lowercase, hyphen-separated)

**Examples**:
- `model-selection-criteria.md`
- `gguf-vs-ggml.md`
- `training-data-requirements.md`

**Auto-generated** based on prompt content for consistency.

### Processed Prompts (Archive)

**Format**: `YYYY-MM/original-name_YYYYMMDD-HHMMSS.ext`

**Examples**:
- `2025-11/model-comparison_20251121-143022.txt`
- `2025-11/quantization-formats_20251121-150445.md`

**Organization**:
- Grouped by year-month folders
- Timestamp appended to prevent conflicts
- Original filename preserved

## Categories

Content is automatically categorized into:

- **models**: ASR model architectures, specific models (Whisper, Wav2Vec, etc.)
- **formats**: File formats, quantization (GGUF, GGML, etc.)
- **training-data**: Datasets, data collection, audio corpus
- **pitfalls**: Common mistakes, problems to avoid
- **fine-tuning**: Training process, hyperparameters, optimization
- **recommendations**: Best practices, advice
- **data-preparation**: Preprocessing, audio cleaning, normalization
- **ext-ref**: External resources, papers, documentation

### How Categorization Works

1. **Keyword matching**: Checks prompt against keyword dictionary in `config.json`
2. **Claude analysis**: If keywords don't match, uses Claude to categorize
3. **Fallback**: Defaults to `ext-ref` if categorization fails

### Customizing Categories

Edit `config.json` to add/modify keywords for each category:

```json
{
  "category_keywords": {
    "models": ["whisper", "wav2vec", "model", ...],
    "formats": ["gguf", "quantization", ...]
  }
}
```

## Attribution

Two forms of attribution are automatically added:

### 1. Shields.io Badge (Top)

```markdown
![Written by Claude](https://img.shields.io/badge/Written%20by-Claude-5A67D8?style=flat-square&logo=anthropic)
```

### 2. Footer (Bottom)

```markdown
---

*Generated by Claude Code - Validate information against current model documentation and benchmarks.*
```

## Command Reference

### Main Processor

```bash
python3 prompt_processor.py [OPTIONS]

Options:
  --dry-run          Show what would be done without doing it
  --prompt FILENAME  Process specific prompt (e.g., 'my-question.txt')
  --api-key KEY      Provide Anthropic API key (or use env var)
```

### Helper Scripts

| Script | Purpose |
|--------|---------|
| `batch_process.sh` | Process all prompts once |
| `watch_and_process.sh` | Continuously monitor and auto-process |
| `create_prompt.sh` | Interactive prompt creation helper |

## Workflow Examples

### Example 1: Add Single Question

```bash
# Create prompt file
echo "What are the key differences between Whisper and Wav2Vec 2.0?" > prompts/to-run/20251121-whisper-vs-wav2vec.txt

# Process it
python3 workflow-automation/prompt_processor.py --prompt 20251121-whisper-vs-wav2vec.txt
```

Result:
- Content generated in `models/whisper-vs-wav2vec.md`
- Original prompt archived to `prompts/processed/2025-11/20251121-whisper-vs-wav2vec_20251121-143522.txt`

### Example 2: Batch Processing

```bash
# Add multiple prompts
echo "How much training data is needed?" > prompts/to-run/20251121-training-volume.txt
echo "Best practices for audio preprocessing?" > prompts/to-run/20251121-preprocessing-tips.txt
echo "Common overfitting problems?" > prompts/to-run/20251121-overfitting.txt

# Process all at once
./workflow-automation/batch_process.sh
```

Result:
- `training-data/training-volume-requirements.md`
- `data-preparation/audio-preprocessing-best-practices.md`
- `pitfalls/overfitting-prevention.md`
- All prompts archived with timestamps

### Example 3: Continuous Workflow

```bash
# Terminal 1: Start watch mode
./workflow-automation/watch_and_process.sh

# Terminal 2: Add prompts as you think of them
./workflow-automation/create_prompt.sh
# (enter your question interactively)
```

Prompts are automatically processed as soon as they're saved.

## Directory Structure

```
STT-Fine-Tuning-Notebook/
├── prompts/
│   ├── to-run/              # New prompts go here
│   └── processed/           # Archived prompts
│       └── YYYY-MM/         # Organized by month
├── workflow-automation/
│   ├── prompt_processor.py  # Main automation script
│   ├── config.json          # Category keywords & settings
│   ├── requirements.txt     # Python dependencies
│   ├── batch_process.sh     # One-time batch processing
│   ├── watch_and_process.sh # Continuous monitoring
│   ├── create_prompt.sh     # Interactive prompt creator
│   └── README.md            # This file
├── models/                  # Generated model notes
├── formats/                 # Generated format notes
├── training-data/           # Generated training data notes
├── pitfalls/                # Generated pitfall notes
├── fine-tuning/             # Generated fine-tuning notes
├── recommendations/         # Generated recommendation notes
├── data-preparation/        # Generated data-prep notes
└── ext-ref/                 # Generated reference notes
```

## Troubleshooting

### "ANTHROPIC_API_KEY not found"

Set the environment variable:
```bash
export ANTHROPIC_API_KEY="your-api-key"
```

Or pass directly:
```bash
python3 prompt_processor.py --api-key "your-api-key"
```

### Watch Mode Not Detecting Files

Install inotify-tools:
```bash
sudo apt install inotify-tools
```

### Duplicate Filenames

The system automatically handles duplicates by appending `-1`, `-2`, etc.

### Content Quality Issues

If generated content isn't meeting expectations:

1. Make prompts more specific and detailed
2. Include examples in your prompt
3. Specify desired format/structure in the prompt
4. Edit the system prompt in `prompt_processor.py` (line 123)

## Extending the System

### Add New Category

1. Create the category folder in repo root
2. Add to `CATEGORY_FOLDERS` dict in `prompt_processor.py` (line 21)
3. Add keywords to `config.json`

### Modify Attribution Format

Edit these constants in `prompt_processor.py` (lines 32-33):
- `ATTRIBUTION_FOOTER`
- `ATTRIBUTION_BADGE`

### Change AI Model

Edit line 106 in `prompt_processor.py`:
```python
model="claude-sonnet-4-5-20250929"  # Change to different model
```

## Performance

- **Categorization**: ~1-2 seconds per prompt (keyword match instant, Claude analysis 1-2s)
- **Content generation**: ~5-15 seconds depending on complexity
- **Total per prompt**: ~10-20 seconds
- **Batch processing**: Processes sequentially to avoid rate limits

## Best Practices

1. **Use descriptive prompt filenames** - helps with organization
2. **Keep prompts focused** - one topic per prompt for better categorization
3. **Review generated content** - always validate technical accuracy
4. **Use watch mode during sessions** - for seamless workflow
5. **Use batch mode for bulk processing** - when you have many prompts queued
6. **Version control regularly** - commit after processing batches

## Integration with Git

After batch processing, commit changes:

```bash
git add models/ formats/ training-data/ # etc.
git add prompts/processed/
git commit -m "Process batch of STT fine-tuning prompts"
git push
```

Or let Claude Code handle it when you ask!

---

*This workflow automation system was designed for efficient, scalable STT notebook content generation.*
